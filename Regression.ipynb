{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5afeaa5-26c9-4488-a210-7586298fbddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Results:\n",
      "--------------------------------------------------\n",
      "\n",
      "Training Linear Regression...\n",
      "Linear Regression:\n",
      "RMSE: 0.2463\n",
      "MAE: 0.1888\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest:\n",
      "RMSE: 0.5041\n",
      "MAE: 0.3440\n",
      "\n",
      "Training Extra Trees...\n",
      "Extra Trees:\n",
      "RMSE: 0.4957\n",
      "MAE: 0.3398\n",
      "\n",
      "Training NGBoost...\n",
      "[iter 0] loss=3.6240 val_loss=0.0000 scale=1.0000 norm=7.8965\n",
      "[iter 100] loss=2.4592 val_loss=0.0000 scale=2.0000 norm=2.5561\n",
      "[iter 200] loss=1.4763 val_loss=0.0000 scale=2.0000 norm=1.1548\n",
      "[iter 300] loss=0.5540 val_loss=0.0000 scale=2.0000 norm=1.0202\n",
      "[iter 400] loss=-0.1393 val_loss=0.0000 scale=2.0000 norm=0.9171\n",
      "NGBoost:\n",
      "RMSE: 0.2312\n",
      "MAE: 0.1633\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost:\n",
      "RMSE: 0.2619\n",
      "MAE: 0.1833\n",
      "\n",
      "Training AdaBoost...\n",
      "AdaBoost:\n",
      "RMSE: 0.5796\n",
      "MAE: 0.4328\n",
      "\n",
      "Final Rankings (sorted by RMSE):\n",
      "--------------------------------------------------\n",
      "NGBoost              - RMSE: 0.2312, MAE: 0.1633\n",
      "Linear Regression    - RMSE: 0.2463, MAE: 0.1888\n",
      "XGBoost              - RMSE: 0.2619, MAE: 0.1833\n",
      "Extra Trees          - RMSE: 0.4957, MAE: 0.3398\n",
      "Random Forest        - RMSE: 0.5041, MAE: 0.3440\n",
      "AdaBoost             - RMSE: 0.5796, MAE: 0.4328\n"
     ]
    }
   ],
   "source": [
    "# 2. Regression:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from ngboost import NGBRegressor\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Remove categorical attributes and select a numerical target variable\n",
    "numerical_data = data.select_dtypes(include=['float64', 'int64'])\n",
    "target_variable = 'temp'\n",
    "\n",
    "# Fill missing values with the most frequent value (mode)\n",
    "for column in numerical_data.columns:\n",
    "    mode_value = numerical_data[column].mode()[0]\n",
    "    numerical_data[column] = numerical_data[column].fillna(mode_value)\n",
    "\n",
    "X = numerical_data.drop(columns=[target_variable]).values\n",
    "y = numerical_data[target_variable].values\n",
    "\n",
    "# Train-test split\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[indices[:train_size]], X[indices[train_size:]]\n",
    "y_train, y_test = y[indices[:train_size]], y[indices[train_size:]]\n",
    "\n",
    "# Evaluation metrics\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "# Linear Regression Implementation\n",
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        self.weights = np.linalg.pinv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        return X_b.dot(self.weights)\n",
    "\n",
    "# Decision Tree Implementation\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=5):\n",
    "        self.tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.tree.fit(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.tree.predict(X)\n",
    "\n",
    "# Random Forest Implementation\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=5):\n",
    "        self.trees = [DecisionTree(max_depth) for _ in range(n_estimators)]\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        for tree in self.trees:\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            tree.fit(X[indices], y[indices])\n",
    "            \n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.mean(predictions, axis=0)\n",
    "\n",
    "# Extra Trees Implementation\n",
    "class ExtraTrees(RandomForest):\n",
    "    def __init__(self, n_estimators=100, max_depth=5):\n",
    "        super().__init__(n_estimators, max_depth)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        for tree in self.trees:\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            # Add random feature selection and split point selection\n",
    "            X_sample = X[indices] + np.random.normal(0, 0.01, X[indices].shape)\n",
    "            tree.fit(X_sample, y[indices])\n",
    "\n",
    "# Fixed AdaBoost Implementation\n",
    "class CustomAdaBoost:\n",
    "    def __init__(self, n_estimators=50):\n",
    "        self.model = AdaBoostRegressor(\n",
    "            DecisionTreeRegressor(max_depth=3),\n",
    "            n_estimators=n_estimators,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# NGBoost Implementation\n",
    "class CustomNGBoost:\n",
    "    def __init__(self):\n",
    "        self.model = NGBRegressor(random_state=42)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# XGBoost Implementation\n",
    "class CustomXGBoost:\n",
    "    def __init__(self):\n",
    "        self.model = XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# Instantiate models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForest(n_estimators=100),\n",
    "    \"Extra Trees\": ExtraTrees(n_estimators=100),\n",
    "    \"NGBoost\": CustomNGBoost(),\n",
    "    \"XGBoost\": CustomXGBoost(),\n",
    "    \"AdaBoost\": CustomAdaBoost(n_estimators=50)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(\"-\" * 50)\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    model_rmse = rmse(y_test, predictions)\n",
    "    model_mae = mae(y_test, predictions)\n",
    "    \n",
    "    results[name] = {\n",
    "        \"RMSE\": model_rmse,\n",
    "        \"MAE\": model_mae\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"RMSE: {model_rmse:.4f}\")\n",
    "    print(f\"MAE: {model_mae:.4f}\")\n",
    "\n",
    "# Sort models by RMSE performance\n",
    "sorted_results = dict(sorted(results.items(), key=lambda x: x[1][\"RMSE\"]))\n",
    "\n",
    "print(\"\\nFinal Rankings (sorted by RMSE):\")\n",
    "print(\"-\" * 50)\n",
    "for model_name, metrics in sorted_results.items():\n",
    "    print(f\"{model_name:20} - RMSE: {metrics['RMSE']:.4f}, MAE: {metrics['MAE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4677946a-af46-4270-ac97-8aa63f70044c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
